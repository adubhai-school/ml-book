# Introduction to PyTorch

Welcome to set of introductory PyTorch lessons.

Here is a list of key concepts and skills we will learn from the PyTorch tutorials shared:

* Basics of PyTorch, understanding what tensors are, and how to perform basic operations on them.
* Usage of torch functions like empty, zeros, ones, and randn.
* Understanding of automatic differentiation mechanism provided by PyTorch's Autograd.
* Understanding the concept of a Linear Layer in a neural network.
* Building a simple linear regression model using PyTorch tensors and Autograd.
* Training a simple linear regression model, including defining a loss function, an optimization function, and updating weights through backpropagation.
* Understanding how to pass data in batches to a model during training.
* Understanding basics of activation functions and how to use them in neural network
* Saving and loading PyTorch models, understanding the difference between saving the whole model and just the state dictionary.
* Understanding the concept of Transfer Learning, how to use pretrained models in PyTorch.
* Learning to modify a pre-trained model for a new task (fine-tuning).
* Recognizing how to use different datasets and how to apply transformations on them using torchvision.transforms.
* Understanding how to evaluate a model by making predictions on test data.
* Simplifying complex neural networks using nn.Sequential in PyTorch.

Each of these concepts builds upon the previous ones, offering a progressive learning curve that covers the essential concepts and skills needed to build, train, and evaluate models with PyTorch.

## Table of contents

- [Tensor Basics](pytorch-1.md)
- [Some common PyTorch methods](pytorch-2.md)
- [Linear Layer](linearlayer.md)
- [A Simple Neural Network](pytorch-3.md)
- [Understanding and Using Activation Functions](activation.md)
- [Simplifying Networks with nn.Sequential](seqmodel.md)
- [Data Loading and Processing](pytorch-4.md)
- [Using a Pretrained Network (Transfer Learning)](pytorch-5.md)

