\section{What is a reward function?}
In reinforcement learning, a reward function is a function that maps each state of the environment to a scalar value, which represents the immediate reward that the agent receives for being in that state. The reward function is defined by the designer of the reinforcement learning problem and reflects the goals and objectives of the problem.

The reward function is used to guide the learning of the agent's policy by assigning a positive or negative reward to each state of the environment, depending on how desirable or undesirable the state is. The agent's objective is to learn a policy that maximizes the expected cumulative reward over time.

The reward function can be designed in various ways, depending on the problem at hand. For example, in a game of chess, the reward function could assign a positive reward for winning the game, a negative reward for losing the game, and zero reward for intermediate moves. In a robotics application, the reward function could assign a positive reward for achieving a desired task, such as reaching a target location, and a negative reward for collisions or other undesirable outcomes.

Designing an appropriate reward function is a crucial step in the reinforcement learning process, as it strongly influences the behavior of the agent and the quality of the learned policy.

